{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f2ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Loss: 41997072.0000\n",
      "Train - Acc: 0.9604, Precision: 0.0000, Recall: 0.0000\n",
      "Train - F1 (Macro): 0.4899, F1 (Micro): 0.9604\n",
      "Train - Specificity: 0.9911, NPV: 0.9688\n",
      "Val - Acc: 0.9545, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4884, F1 (Micro): 0.9545\n",
      "Val - Specificity: 0.9916, NPV: 0.9623\n",
      "---\n",
      "Epoch 2/2000, Loss: 8859517.0000\n",
      "Train - Acc: 0.9604, Precision: 0.0000, Recall: 0.0000\n",
      "Train - F1 (Macro): 0.4899, F1 (Micro): 0.9604\n",
      "Train - Specificity: 0.9911, NPV: 0.9688\n",
      "Val - Acc: 0.9545, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4884, F1 (Micro): 0.9545\n",
      "Val - Specificity: 0.9916, NPV: 0.9623\n",
      "---\n",
      "Epoch 3/2000, Loss: 14263670.0000\n",
      "Train - Acc: 0.9600, Precision: 0.0000, Recall: 0.0000\n",
      "Train - F1 (Macro): 0.4898, F1 (Micro): 0.9600\n",
      "Train - Specificity: 0.9907, NPV: 0.9687\n",
      "Val - Acc: 0.9538, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4882, F1 (Micro): 0.9538\n",
      "Val - Specificity: 0.9909, NPV: 0.9623\n",
      "---\n",
      "Epoch 4/2000, Loss: 17369702.0000\n",
      "Train - Acc: 0.9595, Precision: 0.0000, Recall: 0.0000\n",
      "Train - F1 (Macro): 0.4897, F1 (Micro): 0.9595\n",
      "Train - Specificity: 0.9902, NPV: 0.9687\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 5/2000, Loss: 19178116.0000\n",
      "Train - Acc: 0.9597, Precision: 0.0000, Recall: 0.0000\n",
      "Train - F1 (Macro): 0.4897, F1 (Micro): 0.9597\n",
      "Train - Specificity: 0.9904, NPV: 0.9687\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 6/2000, Loss: 20105816.0000\n",
      "Train - Acc: 0.9599, Precision: 0.0000, Recall: 0.0000\n",
      "Train - F1 (Macro): 0.4898, F1 (Micro): 0.9599\n",
      "Train - Specificity: 0.9905, NPV: 0.9687\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 7/2000, Loss: 20409096.0000\n",
      "Train - Acc: 0.9602, Precision: 0.0000, Recall: 0.0000\n",
      "Train - F1 (Macro): 0.4899, F1 (Micro): 0.9602\n",
      "Train - Specificity: 0.9909, NPV: 0.9687\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 8/2000, Loss: 20273664.0000\n",
      "Train - Acc: 0.9604, Precision: 0.0204, Recall: 0.0059\n",
      "Train - F1 (Macro): 0.4945, F1 (Micro): 0.9604\n",
      "Train - Specificity: 0.9909, NPV: 0.9689\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 9/2000, Loss: 19823806.0000\n",
      "Train - Acc: 0.9602, Precision: 0.0200, Recall: 0.0059\n",
      "Train - F1 (Macro): 0.4944, F1 (Micro): 0.9602\n",
      "Train - Specificity: 0.9907, NPV: 0.9689\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 10/2000, Loss: 19145252.0000\n",
      "Train - Acc: 0.9602, Precision: 0.0200, Recall: 0.0059\n",
      "Train - F1 (Macro): 0.4944, F1 (Micro): 0.9602\n",
      "Train - Specificity: 0.9907, NPV: 0.9689\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 11/2000, Loss: 18299810.0000\n",
      "Train - Acc: 0.9602, Precision: 0.0200, Recall: 0.0059\n",
      "Train - F1 (Macro): 0.4944, F1 (Micro): 0.9602\n",
      "Train - Specificity: 0.9907, NPV: 0.9689\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 12/2000, Loss: 17349056.0000\n",
      "Train - Acc: 0.9602, Precision: 0.0200, Recall: 0.0059\n",
      "Train - F1 (Macro): 0.4944, F1 (Micro): 0.9602\n",
      "Train - Specificity: 0.9907, NPV: 0.9689\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 13/2000, Loss: 16336620.0000\n",
      "Train - Acc: 0.9599, Precision: 0.0192, Recall: 0.0059\n",
      "Train - F1 (Macro): 0.4943, F1 (Micro): 0.9599\n",
      "Train - Specificity: 0.9904, NPV: 0.9689\n",
      "Val - Acc: 0.9531, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4880, F1 (Micro): 0.9531\n",
      "Val - Specificity: 0.9901, NPV: 0.9623\n",
      "---\n",
      "Epoch 14/2000, Loss: 15286964.0000\n",
      "Train - Acc: 0.9599, Precision: 0.0192, Recall: 0.0059\n",
      "Train - F1 (Macro): 0.4943, F1 (Micro): 0.9599\n",
      "Train - Specificity: 0.9904, NPV: 0.9689\n",
      "Val - Acc: 0.9523, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4878, F1 (Micro): 0.9523\n",
      "Val - Specificity: 0.9893, NPV: 0.9622\n",
      "---\n",
      "Epoch 15/2000, Loss: 14222628.0000\n",
      "Train - Acc: 0.9599, Precision: 0.0192, Recall: 0.0059\n",
      "Train - F1 (Macro): 0.4943, F1 (Micro): 0.9599\n",
      "Train - Specificity: 0.9904, NPV: 0.9689\n",
      "Val - Acc: 0.9523, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4878, F1 (Micro): 0.9523\n",
      "Val - Specificity: 0.9893, NPV: 0.9622\n",
      "---\n",
      "Epoch 16/2000, Loss: 13170356.0000\n",
      "Train - Acc: 0.9599, Precision: 0.0192, Recall: 0.0059\n",
      "Train - F1 (Macro): 0.4943, F1 (Micro): 0.9599\n",
      "Train - Specificity: 0.9904, NPV: 0.9689\n",
      "Val - Acc: 0.9516, Precision: 0.0000, Recall: 0.0000\n",
      "Val - F1 (Macro): 0.4876, F1 (Micro): 0.9516\n",
      "Val - Specificity: 0.9886, NPV: 0.9622\n",
      "---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m train_precision \u001b[38;5;241m=\u001b[39m precision_score(y_train\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_preds, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     97\u001b[0m train_recall \u001b[38;5;241m=\u001b[39m recall_score(y_train\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_preds)\n\u001b[1;32m---> 98\u001b[0m train_f1_macro \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m train_f1_micro \u001b[38;5;241m=\u001b[39m f1_score(y_train\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    100\u001b[0m tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m confusion_matrix(y_train\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_preds)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[0;32m   1012\u001b[0m     y_true,\n\u001b[0;32m   1013\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1020\u001b[0m ):\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \n\u001b[0;32m   1023\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[0;32m   1159\u001b[0m     y_true,\n\u001b[0;32m   1160\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1168\u001b[0m ):\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \n\u001b[0;32m   1171\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1377\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1374\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\utils\\multiclass.py:114\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    111\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39munique_values(unique_ys)\n\u001b[1;32m--> 114\u001b[0m ys_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_unique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\utils\\multiclass.py:114\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    111\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39munique_values(unique_ys)\n\u001b[1;32m--> 114\u001b[0m ys_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(chain\u001b[38;5;241m.\u001b[39mfrom_iterable((i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_unique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys))\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\utils\\multiclass.py:26\u001b[0m, in \u001b[0;36m_unique_multiclass\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m     24\u001b[0m xp, is_array_api \u001b[38;5;241m=\u001b[39m get_namespace(y)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_array_api:\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(y)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\utils\\_array_api.py:84\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 读取CSV文件\n",
    "data = pd.read_csv('taiwan_bankrupt_data.csv').dropna()\n",
    "\n",
    "# 分割特征和标签\n",
    "features = data.iloc[:, :-1].values\n",
    "labels = data.iloc[:, -1].values\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2)\n",
    "# 转换为Tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# 定义卷积神经网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #卷积核感受野为5，并将原始数据通道扩展为16\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=5,padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        #感受野升至3*5=16（根据原始数据维度而定），16维数据映射至32\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(1408, 128)  \n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # 添加输入通道维度\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "#         x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型和优化器\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#二分类交叉熵损失\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 记录指标的列表\n",
    "train_acc_list = []\n",
    "train_precision_list = []\n",
    "train_recall_list = []\n",
    "train_f1_macro_list = []\n",
    "train_f1_micro_list = []\n",
    "train_specificity_list = []\n",
    "train_npv_list = []\n",
    "\n",
    "val_acc_list = []\n",
    "val_precision_list = []\n",
    "val_recall_list = []\n",
    "val_f1_macro_list = []\n",
    "val_f1_micro_list = []\n",
    "val_specificity_list = []\n",
    "val_npv_list = []\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 2000\n",
    "#不平衡数据的两类选择置信度，大于0.25的概率即视为阳性样本（小类）\n",
    "threshold = 0.25\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs, eta_min=0, last_epoch=-1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    predictions = (torch.sigmoid(outputs) >= threshold).float().squeeze()\n",
    "    loss = criterion(outputs, y_train.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # 在训练集上计算指标\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_preds = (torch.sigmoid(model(X_train)) >= threshold).float().squeeze().detach().numpy()\n",
    "        train_acc = accuracy_score(y_train.detach().numpy(), train_preds)\n",
    "        train_precision = precision_score(y_train.detach().numpy(), train_preds, zero_division=0)\n",
    "        train_recall = recall_score(y_train.detach().numpy(), train_preds)\n",
    "        train_f1_macro = f1_score(y_train.detach().numpy(), train_preds, average='macro')\n",
    "        train_f1_micro = f1_score(y_train.detach().numpy(), train_preds, average='micro')\n",
    "        tn, fp, fn, tp = confusion_matrix(y_train.detach().numpy(), train_preds).ravel()\n",
    "        train_specificity = tn / (tn + fp)\n",
    "        if tn == 0:\n",
    "            train_npv = 0\n",
    "        else:\n",
    "            train_npv = tn / (tn + fn)\n",
    "\n",
    "    # 在验证集上计算指标\n",
    "    with torch.no_grad():\n",
    "        val_preds = (torch.sigmoid(model(X_val)) >= threshold).float().squeeze().detach().numpy()\n",
    "        val_acc = accuracy_score(y_val.detach().numpy(), val_preds)\n",
    "        val_precision = precision_score(y_val.detach().numpy(), val_preds, zero_division=0)\n",
    "        val_recall = recall_score(y_val.detach().numpy(), val_preds)\n",
    "        val_f1_macro = f1_score(y_val.detach().numpy(), val_preds, average='macro')\n",
    "        val_f1_micro = f1_score(y_val.detach().numpy(), val_preds, average='micro')\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val.detach().numpy(), val_preds).ravel()\n",
    "        val_specificity = tn / (tn + fp)\n",
    "        if tn == 0:\n",
    "            val_npv = 0\n",
    "        else:\n",
    "            val_npv = tn / (tn + fn)\n",
    "\n",
    "#     if val_acc == 1:\n",
    "#         break\n",
    "\n",
    "    # 记录指标\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_precision_list.append(train_precision)\n",
    "    train_recall_list.append(train_recall)\n",
    "    train_f1_macro_list.append(train_f1_macro)\n",
    "    train_f1_micro_list.append(train_f1_micro)\n",
    "    train_specificity_list.append(train_specificity)\n",
    "    train_npv_list.append(train_npv)\n",
    "\n",
    "    val_acc_list.append(val_acc)\n",
    "    val_precision_list.append(val_precision)\n",
    "    val_recall_list.append(val_recall)\n",
    "    val_f1_macro_list.append(val_f1_macro)\n",
    "    val_f1_micro_list.append(val_f1_micro)\n",
    "    val_specificity_list.append(val_specificity)\n",
    "    val_npv_list.append(val_npv)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}')\n",
    "    print(f'Train - Acc: {train_acc:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}')\n",
    "    print(f'Train - F1 (Macro): {train_f1_macro:.4f}, F1 (Micro): {train_f1_micro:.4f}')\n",
    "    print(f'Train - Specificity: {train_specificity:.4f}, NPV: {train_npv:.4f}')\n",
    "    print(f'Val - Acc: {val_acc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}')\n",
    "    print(f'Val - F1 (Macro): {val_f1_macro:.4f}, F1 (Micro): {val_f1_micro:.4f}')\n",
    "    print(f'Val - Specificity: {val_specificity:.4f}, NPV: {val_npv:.4f}')\n",
    "    print('---')\n",
    "\n",
    "# 将训练集和测试集的指标保存为DataFrame\n",
    "train_metrics = pd.DataFrame({\n",
    "    'Accuracy': train_acc_list,\n",
    "    'Precision': train_precision_list,\n",
    "    'Recall': train_recall_list,\n",
    "    'F1 Macro': train_f1_macro_list,\n",
    "    'F1 Micro': train_f1_micro_list,\n",
    "    'Specificity': train_specificity_list,\n",
    "    'NPV': train_npv_list\n",
    "})\n",
    "\n",
    "val_metrics = pd.DataFrame({\n",
    "    'Accuracy': val_acc_list,\n",
    "    'Precision': val_precision_list,\n",
    "    'Recall': val_recall_list,\n",
    "    'F1 Macro': val_f1_macro_list,\n",
    "    'F1 Micro': val_f1_micro_list,\n",
    "    'Specificity': val_specificity_list,\n",
    "    'NPV': val_npv_list\n",
    "})\n",
    "\n",
    "# 打印训练集的指标\n",
    "print(\"Train Metrics:\")\n",
    "print(train_metrics)\n",
    "\n",
    "# 打印验证集的指标\n",
    "print(\"Validation Metrics:\")\n",
    "print(val_metrics)\n",
    "\n",
    "# 绘制指标曲线\n",
    "epochs = range(1, num_epochs+1)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.plot(epochs, train_acc_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_acc_list, 'r', label='Val')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.plot(epochs, train_precision_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_precision_list, 'r', label='Val')\n",
    "plt.title('Precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.plot(epochs, train_recall_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_recall_list, 'r', label='Val')\n",
    "plt.title('Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "plt.plot(epochs, train_npv_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_npv_list, 'r', label='Val')\n",
    "plt.title('NPV')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NPV')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "plt.plot(epochs, train_specificity_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_specificity_list, 'r', label='Val')\n",
    "plt.title('Specificity')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Specificity')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "plt.plot(epochs, train_f1_macro_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_f1_macro_list, 'r', label='Val')\n",
    "plt.title('F1 Macro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Macro')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "plt.plot(epochs, train_f1_micro_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_f1_micro_list, 'r', label='Val')\n",
    "plt.title('F1 Micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Micro')\n",
    "plt.legend()\n",
    "\n",
    "#显示训练曲线\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5c6ac96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy       0.934018\n",
       "Precision      0.132075\n",
       "Recall         0.137255\n",
       "F1 Macro       0.550158\n",
       "F1 Micro       0.934018\n",
       "Specificity    0.964966\n",
       "NPV            0.966438\n",
       "Name: 1999, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics.iloc[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
