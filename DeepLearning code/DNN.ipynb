{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d14b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Loss: 0.7254\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 2/2000, Loss: 0.7061\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 3/2000, Loss: 0.6887\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 4/2000, Loss: 0.6729\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 5/2000, Loss: 0.6584\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 6/2000, Loss: 0.6451\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 7/2000, Loss: 0.6326\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 8/2000, Loss: 0.6209\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 9/2000, Loss: 0.6097\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 10/2000, Loss: 0.5990\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 11/2000, Loss: 0.5887\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 12/2000, Loss: 0.5789\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 13/2000, Loss: 0.5695\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 14/2000, Loss: 0.5606\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 15/2000, Loss: 0.5519\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 16/2000, Loss: 0.5437\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 17/2000, Loss: 0.5358\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 18/2000, Loss: 0.5281\n",
      "Train - Acc: 0.0310, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0300, F1 (Micro): 0.0310\n",
      "Train - Specificity: 0.0000, NPV: 0.0000\n",
      "Val - Acc: 0.0374, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0360, F1 (Micro): 0.0374\n",
      "Val - Specificity: 0.0000, NPV: 0.0000\n",
      "---\n",
      "Epoch 19/2000, Loss: 0.5208\n",
      "Train - Acc: 0.0317, Precision: 0.0310, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0308, F1 (Micro): 0.0317\n",
      "Train - Specificity: 0.0008, NPV: 1.0000\n",
      "Val - Acc: 0.0381, Precision: 0.0374, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0368, F1 (Micro): 0.0381\n",
      "Val - Specificity: 0.0008, NPV: 1.0000\n",
      "---\n",
      "Epoch 20/2000, Loss: 0.5137\n",
      "Train - Acc: 0.0334, Precision: 0.0311, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0326, F1 (Micro): 0.0334\n",
      "Train - Specificity: 0.0025, NPV: 1.0000\n",
      "Val - Acc: 0.0403, Precision: 0.0375, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0392, F1 (Micro): 0.0403\n",
      "Val - Specificity: 0.0030, NPV: 1.0000\n",
      "---\n",
      "Epoch 21/2000, Loss: 0.5069\n",
      "Train - Acc: 0.0354, Precision: 0.0311, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0347, F1 (Micro): 0.0354\n",
      "Train - Specificity: 0.0045, NPV: 1.0000\n",
      "Val - Acc: 0.0425, Precision: 0.0376, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0415, F1 (Micro): 0.0425\n",
      "Val - Specificity: 0.0053, NPV: 1.0000\n",
      "---\n",
      "Epoch 22/2000, Loss: 0.5003\n",
      "Train - Acc: 0.0396, Precision: 0.0312, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0391, F1 (Micro): 0.0396\n",
      "Train - Specificity: 0.0089, NPV: 1.0000\n",
      "Val - Acc: 0.0462, Precision: 0.0377, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0454, F1 (Micro): 0.0462\n",
      "Val - Specificity: 0.0091, NPV: 1.0000\n",
      "---\n",
      "Epoch 23/2000, Loss: 0.4941\n",
      "Train - Acc: 0.0478, Precision: 0.0315, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0477, F1 (Micro): 0.0478\n",
      "Train - Specificity: 0.0174, NPV: 1.0000\n",
      "Val - Acc: 0.0535, Precision: 0.0380, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0531, F1 (Micro): 0.0535\n",
      "Val - Specificity: 0.0168, NPV: 1.0000\n",
      "---\n",
      "Epoch 24/2000, Loss: 0.4880\n",
      "Train - Acc: 0.0555, Precision: 0.0318, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0555, F1 (Micro): 0.0555\n",
      "Train - Specificity: 0.0253, NPV: 1.0000\n",
      "Val - Acc: 0.0609, Precision: 0.0383, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0607, F1 (Micro): 0.0609\n",
      "Val - Specificity: 0.0244, NPV: 1.0000\n",
      "---\n",
      "Epoch 25/2000, Loss: 0.4822\n",
      "Train - Acc: 0.0682, Precision: 0.0322, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0682, F1 (Micro): 0.0682\n",
      "Train - Specificity: 0.0384, NPV: 1.0000\n",
      "Val - Acc: 0.0740, Precision: 0.0388, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0740, F1 (Micro): 0.0740\n",
      "Val - Specificity: 0.0381, NPV: 1.0000\n",
      "---\n",
      "Epoch 26/2000, Loss: 0.4767\n",
      "Train - Acc: 0.0843, Precision: 0.0327, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.0839, F1 (Micro): 0.0843\n",
      "Train - Specificity: 0.0551, NPV: 1.0000\n",
      "Val - Acc: 0.0865, Precision: 0.0393, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.0864, F1 (Micro): 0.0865\n",
      "Val - Specificity: 0.0510, NPV: 1.0000\n",
      "---\n",
      "Epoch 27/2000, Loss: 0.4713\n",
      "Train - Acc: 0.1043, Precision: 0.0334, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.1027, F1 (Micro): 0.1043\n",
      "Train - Specificity: 0.0757, NPV: 1.0000\n",
      "Val - Acc: 0.1070, Precision: 0.0402, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.1061, F1 (Micro): 0.1070\n",
      "Val - Specificity: 0.0724, NPV: 1.0000\n",
      "---\n",
      "Epoch 28/2000, Loss: 0.4662\n",
      "Train - Acc: 0.1269, Precision: 0.0343, Recall: 1.0000\n",
      "Train - F1 (Macro): 0.1232, F1 (Micro): 0.1269\n",
      "Train - Specificity: 0.0989, NPV: 1.0000\n",
      "Val - Acc: 0.1246, Precision: 0.0410, Recall: 1.0000\n",
      "Val - F1 (Macro): 0.1225, F1 (Micro): 0.1246\n",
      "Val - Specificity: 0.0906, NPV: 1.0000\n",
      "---\n",
      "Epoch 29/2000, Loss: 0.4613\n",
      "Train - Acc: 0.1549, Precision: 0.0350, Recall: 0.9882\n",
      "Train - F1 (Macro): 0.1474, F1 (Micro): 0.1549\n",
      "Train - Specificity: 0.1283, NPV: 0.9971\n",
      "Val - Acc: 0.1628, Precision: 0.0420, Recall: 0.9804\n",
      "Val - F1 (Macro): 0.1560, F1 (Micro): 0.1628\n",
      "Val - Specificity: 0.1310, NPV: 0.9942\n",
      "---\n",
      "Epoch 30/2000, Loss: 0.4566\n",
      "Train - Acc: 0.1826, Precision: 0.0361, Recall: 0.9882\n",
      "Train - F1 (Macro): 0.1704, F1 (Micro): 0.1826\n",
      "Train - Specificity: 0.1568, NPV: 0.9976\n",
      "Val - Acc: 0.1913, Precision: 0.0426, Recall: 0.9608\n",
      "Val - F1 (Macro): 0.1796, F1 (Micro): 0.1913\n",
      "Val - Specificity: 0.1615, NPV: 0.9907\n",
      "---\n",
      "Epoch 31/2000, Loss: 0.4521\n",
      "Train - Acc: 0.2101, Precision: 0.0371, Recall: 0.9822\n",
      "Train - F1 (Macro): 0.1921, F1 (Micro): 0.2101\n",
      "Train - Specificity: 0.1854, NPV: 0.9969\n",
      "Val - Acc: 0.2177, Precision: 0.0432, Recall: 0.9412\n",
      "Val - F1 (Macro): 0.2004, F1 (Micro): 0.2177\n",
      "Val - Specificity: 0.1896, NPV: 0.9881\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/2000, Loss: 0.4478\n",
      "Train - Acc: 0.2445, Precision: 0.0385, Recall: 0.9763\n",
      "Train - F1 (Macro): 0.2181, F1 (Micro): 0.2445\n",
      "Train - Specificity: 0.2212, NPV: 0.9966\n",
      "Val - Acc: 0.2441, Precision: 0.0438, Recall: 0.9216\n",
      "Val - F1 (Macro): 0.2202, F1 (Micro): 0.2441\n",
      "Val - Specificity: 0.2178, NPV: 0.9862\n",
      "---\n",
      "Epoch 33/2000, Loss: 0.4436\n",
      "Train - Acc: 0.2796, Precision: 0.0403, Recall: 0.9763\n",
      "Train - F1 (Macro): 0.2432, F1 (Micro): 0.2796\n",
      "Train - Specificity: 0.2573, NPV: 0.9971\n",
      "Val - Acc: 0.2757, Precision: 0.0447, Recall: 0.9020\n",
      "Val - F1 (Macro): 0.2428, F1 (Micro): 0.2757\n",
      "Val - Specificity: 0.2513, NPV: 0.9851\n",
      "---\n",
      "Epoch 34/2000, Loss: 0.4396\n",
      "Train - Acc: 0.3096, Precision: 0.0413, Recall: 0.9586\n",
      "Train - F1 (Macro): 0.2635, F1 (Micro): 0.3096\n",
      "Train - Specificity: 0.2889, NPV: 0.9954\n",
      "Val - Acc: 0.3006, Precision: 0.0453, Recall: 0.8824\n",
      "Val - F1 (Macro): 0.2598, F1 (Micro): 0.3006\n",
      "Val - Specificity: 0.2780, NPV: 0.9838\n",
      "---\n",
      "Epoch 35/2000, Loss: 0.4357\n",
      "Train - Acc: 0.3340, Precision: 0.0420, Recall: 0.9408\n",
      "Train - F1 (Macro): 0.2792, F1 (Micro): 0.3340\n",
      "Train - Specificity: 0.3146, NPV: 0.9940\n",
      "Val - Acc: 0.3343, Precision: 0.0475, Recall: 0.8824\n",
      "Val - F1 (Macro): 0.2827, F1 (Micro): 0.3343\n",
      "Val - Specificity: 0.3130, NPV: 0.9856\n",
      "---\n",
      "Epoch 36/2000, Loss: 0.4320\n",
      "Train - Acc: 0.3608, Precision: 0.0430, Recall: 0.9231\n",
      "Train - F1 (Macro): 0.2959, F1 (Micro): 0.3608\n",
      "Train - Specificity: 0.3428, NPV: 0.9929\n",
      "Val - Acc: 0.3563, Precision: 0.0491, Recall: 0.8824\n",
      "Val - F1 (Macro): 0.2971, F1 (Micro): 0.3563\n",
      "Val - Specificity: 0.3359, NPV: 0.9866\n",
      "---\n",
      "Epoch 37/2000, Loss: 0.4283\n",
      "Train - Acc: 0.3923, Precision: 0.0443, Recall: 0.9053\n",
      "Train - F1 (Macro): 0.3149, F1 (Micro): 0.3923\n",
      "Train - Specificity: 0.3759, NPV: 0.9920\n",
      "Val - Acc: 0.3820, Precision: 0.0510, Recall: 0.8824\n",
      "Val - F1 (Macro): 0.3134, F1 (Micro): 0.3820\n",
      "Val - Specificity: 0.3625, NPV: 0.9876\n",
      "---\n",
      "Epoch 38/2000, Loss: 0.4248\n",
      "Train - Acc: 0.4359, Precision: 0.0476, Recall: 0.9053\n",
      "Train - F1 (Macro): 0.3408, F1 (Micro): 0.4359\n",
      "Train - Specificity: 0.4209, NPV: 0.9929\n",
      "Val - Acc: 0.4289, Precision: 0.0550, Recall: 0.8824\n",
      "Val - F1 (Macro): 0.3423, F1 (Micro): 0.4289\n",
      "Val - Specificity: 0.4113, NPV: 0.9890\n",
      "---\n",
      "Epoch 39/2000, Loss: 0.4215\n",
      "Train - Acc: 0.4610, Precision: 0.0494, Recall: 0.8994\n",
      "Train - F1 (Macro): 0.3551, F1 (Micro): 0.4610\n",
      "Train - Specificity: 0.4470, NPV: 0.9929\n",
      "Val - Acc: 0.4479, Precision: 0.0557, Recall: 0.8627\n",
      "Val - F1 (Macro): 0.3528, F1 (Micro): 0.4479\n",
      "Val - Specificity: 0.4318, NPV: 0.9878\n",
      "---\n",
      "Epoch 40/2000, Loss: 0.4182\n",
      "Train - Acc: 0.4880, Precision: 0.0519, Recall: 0.8994\n",
      "Train - F1 (Macro): 0.3703, F1 (Micro): 0.4880\n",
      "Train - Specificity: 0.4748, NPV: 0.9933\n",
      "Val - Acc: 0.4758, Precision: 0.0573, Recall: 0.8431\n",
      "Val - F1 (Macro): 0.3682, F1 (Micro): 0.4758\n",
      "Val - Specificity: 0.4615, NPV: 0.9870\n",
      "---\n",
      "Epoch 41/2000, Loss: 0.4151\n",
      "Train - Acc: 0.5098, Precision: 0.0538, Recall: 0.8935\n",
      "Train - F1 (Macro): 0.3822, F1 (Micro): 0.5098\n",
      "Train - Specificity: 0.4975, NPV: 0.9932\n",
      "Val - Acc: 0.4941, Precision: 0.0593, Recall: 0.8431\n",
      "Val - F1 (Macro): 0.3787, F1 (Micro): 0.4941\n",
      "Val - Specificity: 0.4806, NPV: 0.9875\n",
      "---\n",
      "Epoch 42/2000, Loss: 0.4120\n",
      "Train - Acc: 0.5360, Precision: 0.0567, Recall: 0.8935\n",
      "Train - F1 (Macro): 0.3966, F1 (Micro): 0.5360\n",
      "Train - Specificity: 0.5246, NPV: 0.9936\n",
      "Val - Acc: 0.5154, Precision: 0.0580, Recall: 0.7843\n",
      "Val - F1 (Macro): 0.3876, F1 (Micro): 0.5154\n",
      "Val - Specificity: 0.5050, NPV: 0.9837\n",
      "---\n",
      "Epoch 43/2000, Loss: 0.4091\n",
      "Train - Acc: 0.5619, Precision: 0.0598, Recall: 0.8935\n",
      "Train - F1 (Macro): 0.4107, F1 (Micro): 0.5619\n",
      "Train - Specificity: 0.5513, NPV: 0.9939\n",
      "Val - Acc: 0.5359, Precision: 0.0591, Recall: 0.7647\n",
      "Val - F1 (Macro): 0.3979, F1 (Micro): 0.5359\n",
      "Val - Specificity: 0.5270, NPV: 0.9830\n",
      "---\n",
      "Epoch 44/2000, Loss: 0.4062\n",
      "Train - Acc: 0.5859, Precision: 0.0620, Recall: 0.8757\n",
      "Train - F1 (Macro): 0.4227, F1 (Micro): 0.5859\n",
      "Train - Specificity: 0.5766, NPV: 0.9932\n",
      "Val - Acc: 0.5660, Precision: 0.0630, Recall: 0.7647\n",
      "Val - F1 (Macro): 0.4144, F1 (Micro): 0.5660\n",
      "Val - Specificity: 0.5583, NPV: 0.9839\n",
      "---\n",
      "Epoch 45/2000, Loss: 0.4034\n",
      "Train - Acc: 0.6068, Precision: 0.0648, Recall: 0.8698\n",
      "Train - F1 (Macro): 0.4337, F1 (Micro): 0.6068\n",
      "Train - Specificity: 0.5984, NPV: 0.9931\n",
      "Val - Acc: 0.5843, Precision: 0.0657, Recall: 0.7647\n",
      "Val - F1 (Macro): 0.4244, F1 (Micro): 0.5843\n",
      "Val - Specificity: 0.5773, NPV: 0.9844\n",
      "---\n",
      "Epoch 46/2000, Loss: 0.4007\n",
      "Train - Acc: 0.6235, Precision: 0.0667, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.4420, F1 (Micro): 0.6235\n",
      "Train - Specificity: 0.6160, NPV: 0.9927\n",
      "Val - Acc: 0.5997, Precision: 0.0681, Recall: 0.7647\n",
      "Val - F1 (Macro): 0.4327, F1 (Micro): 0.5997\n",
      "Val - Specificity: 0.5933, NPV: 0.9848\n",
      "---\n",
      "Epoch 47/2000, Loss: 0.3982\n",
      "Train - Acc: 0.6376, Precision: 0.0679, Recall: 0.8402\n",
      "Train - F1 (Macro): 0.4485, F1 (Micro): 0.6376\n",
      "Train - Specificity: 0.6311, NPV: 0.9920\n",
      "Val - Acc: 0.6166, Precision: 0.0709, Recall: 0.7647\n",
      "Val - F1 (Macro): 0.4419, F1 (Micro): 0.6166\n",
      "Val - Specificity: 0.6108, NPV: 0.9853\n",
      "---\n",
      "Epoch 48/2000, Loss: 0.3957\n",
      "Train - Acc: 0.6493, Precision: 0.0692, Recall: 0.8284\n",
      "Train - F1 (Macro): 0.4541, F1 (Micro): 0.6493\n",
      "Train - Specificity: 0.6436, NPV: 0.9915\n",
      "Val - Acc: 0.6298, Precision: 0.0717, Recall: 0.7451\n",
      "Val - F1 (Macro): 0.4478, F1 (Micro): 0.6298\n",
      "Val - Specificity: 0.6253, NPV: 0.9844\n",
      "---\n",
      "Epoch 49/2000, Loss: 0.3933\n",
      "Train - Acc: 0.6588, Precision: 0.0706, Recall: 0.8225\n",
      "Train - F1 (Macro): 0.4589, F1 (Micro): 0.6588\n",
      "Train - Specificity: 0.6536, NPV: 0.9914\n",
      "Val - Acc: 0.6349, Precision: 0.0710, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4492, F1 (Micro): 0.6349\n",
      "Val - Specificity: 0.6314, NPV: 0.9834\n",
      "---\n",
      "Epoch 50/2000, Loss: 0.3909\n",
      "Train - Acc: 0.6664, Precision: 0.0716, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.4626, F1 (Micro): 0.6664\n",
      "Train - Specificity: 0.6616, NPV: 0.9912\n",
      "Val - Acc: 0.6415, Precision: 0.0723, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4528, F1 (Micro): 0.6415\n",
      "Val - Specificity: 0.6382, NPV: 0.9836\n",
      "---\n",
      "Epoch 51/2000, Loss: 0.3887\n",
      "Train - Acc: 0.6763, Precision: 0.0737, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.4680, F1 (Micro): 0.6763\n",
      "Train - Specificity: 0.6718, NPV: 0.9913\n",
      "Val - Acc: 0.6518, Precision: 0.0743, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4584, F1 (Micro): 0.6518\n",
      "Val - Specificity: 0.6489, NPV: 0.9838\n",
      "---\n",
      "Epoch 52/2000, Loss: 0.3865\n",
      "Train - Acc: 0.6865, Precision: 0.0759, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.4737, F1 (Micro): 0.6865\n",
      "Train - Specificity: 0.6824, NPV: 0.9915\n",
      "Val - Acc: 0.6613, Precision: 0.0763, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4636, F1 (Micro): 0.6613\n",
      "Val - Specificity: 0.6588, NPV: 0.9841\n",
      "---\n",
      "Epoch 53/2000, Loss: 0.3844\n",
      "Train - Acc: 0.6940, Precision: 0.0777, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.4779, F1 (Micro): 0.6940\n",
      "Train - Specificity: 0.6901, NPV: 0.9916\n",
      "Val - Acc: 0.6664, Precision: 0.0774, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4665, F1 (Micro): 0.6664\n",
      "Val - Specificity: 0.6641, NPV: 0.9842\n",
      "---\n",
      "Epoch 54/2000, Loss: 0.3823\n",
      "Train - Acc: 0.7032, Precision: 0.0800, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.4830, F1 (Micro): 0.7032\n",
      "Train - Specificity: 0.6996, NPV: 0.9917\n",
      "Val - Acc: 0.6760, Precision: 0.0796, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4718, F1 (Micro): 0.6760\n",
      "Val - Specificity: 0.6740, NPV: 0.9844\n",
      "---\n",
      "Epoch 55/2000, Loss: 0.3803\n",
      "Train - Acc: 0.7120, Precision: 0.0822, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.4880, F1 (Micro): 0.7120\n",
      "Train - Specificity: 0.7087, NPV: 0.9918\n",
      "Val - Acc: 0.6818, Precision: 0.0810, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4751, F1 (Micro): 0.6818\n",
      "Val - Specificity: 0.6801, NPV: 0.9846\n",
      "---\n",
      "Epoch 56/2000, Loss: 0.3783\n",
      "Train - Acc: 0.7214, Precision: 0.0853, Recall: 0.8225\n",
      "Train - F1 (Macro): 0.4939, F1 (Micro): 0.7214\n",
      "Train - Specificity: 0.7181, NPV: 0.9922\n",
      "Val - Acc: 0.6899, Precision: 0.0830, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4796, F1 (Micro): 0.6899\n",
      "Val - Specificity: 0.6885, NPV: 0.9847\n",
      "---\n",
      "Epoch 57/2000, Loss: 0.3763\n",
      "Train - Acc: 0.7278, Precision: 0.0872, Recall: 0.8225\n",
      "Train - F1 (Macro): 0.4977, F1 (Micro): 0.7278\n",
      "Train - Specificity: 0.7247, NPV: 0.9922\n",
      "Val - Acc: 0.6965, Precision: 0.0847, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4834, F1 (Micro): 0.6965\n",
      "Val - Specificity: 0.6954, NPV: 0.9849\n",
      "---\n",
      "Epoch 58/2000, Loss: 0.3744\n",
      "Train - Acc: 0.7340, Precision: 0.0891, Recall: 0.8225\n",
      "Train - F1 (Macro): 0.5014, F1 (Micro): 0.7340\n",
      "Train - Specificity: 0.7312, NPV: 0.9923\n",
      "Val - Acc: 0.7023, Precision: 0.0862, Recall: 0.7255\n",
      "Val - F1 (Macro): 0.4868, F1 (Micro): 0.7023\n",
      "Val - Specificity: 0.7014, NPV: 0.9850\n",
      "---\n",
      "Epoch 59/2000, Loss: 0.3726\n",
      "Train - Acc: 0.7401, Precision: 0.0910, Recall: 0.8225\n",
      "Train - F1 (Macro): 0.5050, F1 (Micro): 0.7401\n",
      "Train - Specificity: 0.7374, NPV: 0.9924\n",
      "Val - Acc: 0.7067, Precision: 0.0855, Recall: 0.7059\n",
      "Val - F1 (Macro): 0.4876, F1 (Micro): 0.7067\n",
      "Val - Specificity: 0.7068, NPV: 0.9841\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/2000, Loss: 0.3707\n",
      "Train - Acc: 0.7437, Precision: 0.0917, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.5068, F1 (Micro): 0.7437\n",
      "Train - Specificity: 0.7414, NPV: 0.9922\n",
      "Val - Acc: 0.7133, Precision: 0.0874, Recall: 0.7059\n",
      "Val - F1 (Macro): 0.4914, F1 (Micro): 0.7133\n",
      "Val - Specificity: 0.7136, NPV: 0.9842\n",
      "---\n",
      "Epoch 61/2000, Loss: 0.3689\n",
      "Train - Acc: 0.7474, Precision: 0.0924, Recall: 0.8107\n",
      "Train - F1 (Macro): 0.5085, F1 (Micro): 0.7474\n",
      "Train - Specificity: 0.7454, NPV: 0.9919\n",
      "Val - Acc: 0.7192, Precision: 0.0891, Recall: 0.7059\n",
      "Val - F1 (Macro): 0.4949, F1 (Micro): 0.7192\n",
      "Val - Specificity: 0.7197, NPV: 0.9844\n",
      "---\n",
      "Epoch 62/2000, Loss: 0.3672\n",
      "Train - Acc: 0.7512, Precision: 0.0937, Recall: 0.8107\n",
      "Train - F1 (Macro): 0.5109, F1 (Micro): 0.7512\n",
      "Train - Specificity: 0.7493, NPV: 0.9920\n",
      "Val - Acc: 0.7236, Precision: 0.0884, Recall: 0.6863\n",
      "Val - F1 (Macro): 0.4957, F1 (Micro): 0.7236\n",
      "Val - Specificity: 0.7251, NPV: 0.9835\n",
      "---\n",
      "Epoch 63/2000, Loss: 0.3655\n",
      "Train - Acc: 0.7556, Precision: 0.0953, Recall: 0.8107\n",
      "Train - F1 (Macro): 0.5136, F1 (Micro): 0.7556\n",
      "Train - Specificity: 0.7539, NPV: 0.9920\n",
      "Val - Acc: 0.7287, Precision: 0.0900, Recall: 0.6863\n",
      "Val - F1 (Macro): 0.4987, F1 (Micro): 0.7287\n",
      "Val - Specificity: 0.7304, NPV: 0.9836\n",
      "---\n",
      "Epoch 64/2000, Loss: 0.3638\n",
      "Train - Acc: 0.7577, Precision: 0.0960, Recall: 0.8107\n",
      "Train - F1 (Macro): 0.5149, F1 (Micro): 0.7577\n",
      "Train - Specificity: 0.7560, NPV: 0.9921\n",
      "Val - Acc: 0.7309, Precision: 0.0907, Recall: 0.6863\n",
      "Val - F1 (Macro): 0.5000, F1 (Micro): 0.7309\n",
      "Val - Specificity: 0.7327, NPV: 0.9836\n",
      "---\n",
      "Epoch 65/2000, Loss: 0.3622\n",
      "Train - Acc: 0.7595, Precision: 0.0967, Recall: 0.8107\n",
      "Train - F1 (Macro): 0.5160, F1 (Micro): 0.7595\n",
      "Train - Specificity: 0.7579, NPV: 0.9921\n",
      "Val - Acc: 0.7346, Precision: 0.0919, Recall: 0.6863\n",
      "Val - F1 (Macro): 0.5022, F1 (Micro): 0.7346\n",
      "Val - Specificity: 0.7365, NPV: 0.9837\n",
      "---\n",
      "Epoch 66/2000, Loss: 0.3605\n",
      "Train - Acc: 0.7613, Precision: 0.0979, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.5177, F1 (Micro): 0.7613\n",
      "Train - Specificity: 0.7596, NPV: 0.9923\n",
      "Val - Acc: 0.7361, Precision: 0.0923, Recall: 0.6863\n",
      "Val - F1 (Macro): 0.5031, F1 (Micro): 0.7361\n",
      "Val - Specificity: 0.7380, NPV: 0.9838\n",
      "---\n",
      "Epoch 67/2000, Loss: 0.3590\n",
      "Train - Acc: 0.7622, Precision: 0.0983, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.5183, F1 (Micro): 0.7622\n",
      "Train - Specificity: 0.7605, NPV: 0.9923\n",
      "Val - Acc: 0.7375, Precision: 0.0928, Recall: 0.6863\n",
      "Val - F1 (Macro): 0.5039, F1 (Micro): 0.7375\n",
      "Val - Specificity: 0.7395, NPV: 0.9838\n",
      "---\n",
      "Epoch 68/2000, Loss: 0.3574\n",
      "Train - Acc: 0.7617, Precision: 0.0981, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.5179, F1 (Micro): 0.7617\n",
      "Train - Specificity: 0.7599, NPV: 0.9923\n",
      "Val - Acc: 0.7368, Precision: 0.0926, Recall: 0.6863\n",
      "Val - F1 (Macro): 0.5035, F1 (Micro): 0.7368\n",
      "Val - Specificity: 0.7388, NPV: 0.9838\n",
      "---\n",
      "Epoch 69/2000, Loss: 0.3559\n",
      "Train - Acc: 0.7626, Precision: 0.0984, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.5185, F1 (Micro): 0.7626\n",
      "Train - Specificity: 0.7609, NPV: 0.9924\n",
      "Val - Acc: 0.7353, Precision: 0.0899, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.5007, F1 (Micro): 0.7353\n",
      "Val - Specificity: 0.7380, NPV: 0.9828\n",
      "---\n",
      "Epoch 70/2000, Loss: 0.3544\n",
      "Train - Acc: 0.7635, Precision: 0.0988, Recall: 0.8166\n",
      "Train - F1 (Macro): 0.5191, F1 (Micro): 0.7635\n",
      "Train - Specificity: 0.7618, NPV: 0.9924\n",
      "Val - Acc: 0.7375, Precision: 0.0907, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.5021, F1 (Micro): 0.7375\n",
      "Val - Specificity: 0.7403, NPV: 0.9828\n",
      "---\n",
      "Epoch 71/2000, Loss: 0.3530\n",
      "Train - Acc: 0.7639, Precision: 0.0995, Recall: 0.8225\n",
      "Train - F1 (Macro): 0.5198, F1 (Micro): 0.7639\n",
      "Train - Specificity: 0.7620, NPV: 0.9926\n",
      "Val - Acc: 0.7390, Precision: 0.0912, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.5029, F1 (Micro): 0.7390\n",
      "Val - Specificity: 0.7418, NPV: 0.9828\n",
      "---\n",
      "Epoch 72/2000, Loss: 0.3515\n",
      "Train - Acc: 0.7643, Precision: 0.0996, Recall: 0.8225\n",
      "Train - F1 (Macro): 0.5201, F1 (Micro): 0.7643\n",
      "Train - Specificity: 0.7624, NPV: 0.9926\n",
      "Val - Acc: 0.7397, Precision: 0.0914, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.5034, F1 (Micro): 0.7397\n",
      "Val - Specificity: 0.7426, NPV: 0.9829\n",
      "---\n",
      "Epoch 73/2000, Loss: 0.3501\n",
      "Train - Acc: 0.7648, Precision: 0.1004, Recall: 0.8284\n",
      "Train - F1 (Macro): 0.5209, F1 (Micro): 0.7648\n",
      "Train - Specificity: 0.7628, NPV: 0.9929\n",
      "Val - Acc: 0.7412, Precision: 0.0919, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.5043, F1 (Micro): 0.7412\n",
      "Val - Specificity: 0.7441, NPV: 0.9829\n",
      "---\n",
      "Epoch 74/2000, Loss: 0.3487\n",
      "Train - Acc: 0.7633, Precision: 0.0999, Recall: 0.8284\n",
      "Train - F1 (Macro): 0.5200, F1 (Micro): 0.7633\n",
      "Train - Specificity: 0.7613, NPV: 0.9928\n",
      "Val - Acc: 0.7390, Precision: 0.0912, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.5029, F1 (Micro): 0.7390\n",
      "Val - Specificity: 0.7418, NPV: 0.9828\n",
      "---\n",
      "Epoch 75/2000, Loss: 0.3474\n",
      "Train - Acc: 0.7624, Precision: 0.0995, Recall: 0.8284\n",
      "Train - F1 (Macro): 0.5194, F1 (Micro): 0.7624\n",
      "Train - Specificity: 0.7603, NPV: 0.9928\n",
      "Val - Acc: 0.7368, Precision: 0.0904, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.5016, F1 (Micro): 0.7368\n",
      "Val - Specificity: 0.7395, NPV: 0.9828\n",
      "---\n",
      "Epoch 76/2000, Loss: 0.3460\n",
      "Train - Acc: 0.7622, Precision: 0.0994, Recall: 0.8284\n",
      "Train - F1 (Macro): 0.5193, F1 (Micro): 0.7622\n",
      "Train - Specificity: 0.7601, NPV: 0.9928\n",
      "Val - Acc: 0.7339, Precision: 0.0895, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.4999, F1 (Micro): 0.7339\n",
      "Val - Specificity: 0.7365, NPV: 0.9827\n",
      "---\n",
      "Epoch 77/2000, Loss: 0.3447\n",
      "Train - Acc: 0.7622, Precision: 0.0994, Recall: 0.8284\n",
      "Train - F1 (Macro): 0.5193, F1 (Micro): 0.7622\n",
      "Train - Specificity: 0.7601, NPV: 0.9928\n",
      "Val - Acc: 0.7368, Precision: 0.0904, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.5016, F1 (Micro): 0.7368\n",
      "Val - Specificity: 0.7395, NPV: 0.9828\n",
      "---\n",
      "Epoch 78/2000, Loss: 0.3434\n",
      "Train - Acc: 0.7621, Precision: 0.0994, Recall: 0.8284\n",
      "Train - F1 (Macro): 0.5192, F1 (Micro): 0.7621\n",
      "Train - Specificity: 0.7599, NPV: 0.9928\n",
      "Val - Acc: 0.7353, Precision: 0.0899, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.5007, F1 (Micro): 0.7353\n",
      "Val - Specificity: 0.7380, NPV: 0.9828\n",
      "---\n",
      "Epoch 79/2000, Loss: 0.3421\n",
      "Train - Acc: 0.7637, Precision: 0.1000, Recall: 0.8284\n",
      "Train - F1 (Macro): 0.5202, F1 (Micro): 0.7637\n",
      "Train - Specificity: 0.7616, NPV: 0.9928\n",
      "Val - Acc: 0.7331, Precision: 0.0892, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.4994, F1 (Micro): 0.7331\n",
      "Val - Specificity: 0.7357, NPV: 0.9827\n",
      "---\n",
      "Epoch 80/2000, Loss: 0.3408\n",
      "Train - Acc: 0.7648, Precision: 0.1010, Recall: 0.8343\n",
      "Train - F1 (Macro): 0.5214, F1 (Micro): 0.7648\n",
      "Train - Specificity: 0.7626, NPV: 0.9931\n",
      "Val - Acc: 0.7331, Precision: 0.0892, Recall: 0.6667\n",
      "Val - F1 (Macro): 0.4994, F1 (Micro): 0.7331\n",
      "Val - Specificity: 0.7357, NPV: 0.9827\n",
      "---\n",
      "Epoch 81/2000, Loss: 0.3396\n",
      "Train - Acc: 0.7659, Precision: 0.1020, Recall: 0.8402\n",
      "Train - F1 (Macro): 0.5227, F1 (Micro): 0.7659\n",
      "Train - Specificity: 0.7635, NPV: 0.9934\n",
      "Val - Acc: 0.7324, Precision: 0.0868, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.4971, F1 (Micro): 0.7324\n",
      "Val - Specificity: 0.7357, NPV: 0.9817\n",
      "---\n",
      "Epoch 82/2000, Loss: 0.3383\n",
      "Train - Acc: 0.7654, Precision: 0.1018, Recall: 0.8402\n",
      "Train - F1 (Macro): 0.5223, F1 (Micro): 0.7654\n",
      "Train - Specificity: 0.7630, NPV: 0.9933\n",
      "Val - Acc: 0.7339, Precision: 0.0873, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.4980, F1 (Micro): 0.7339\n",
      "Val - Specificity: 0.7372, NPV: 0.9817\n",
      "---\n",
      "Epoch 83/2000, Loss: 0.3371\n",
      "Train - Acc: 0.7659, Precision: 0.1026, Recall: 0.8462\n",
      "Train - F1 (Macro): 0.5232, F1 (Micro): 0.7659\n",
      "Train - Specificity: 0.7633, NPV: 0.9936\n",
      "Val - Acc: 0.7353, Precision: 0.0878, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.4988, F1 (Micro): 0.7353\n",
      "Val - Specificity: 0.7388, NPV: 0.9818\n",
      "---\n",
      "Epoch 84/2000, Loss: 0.3358\n",
      "Train - Acc: 0.7670, Precision: 0.1030, Recall: 0.8462\n",
      "Train - F1 (Macro): 0.5239, F1 (Micro): 0.7670\n",
      "Train - Specificity: 0.7645, NPV: 0.9936\n",
      "Val - Acc: 0.7361, Precision: 0.0880, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.4993, F1 (Micro): 0.7361\n",
      "Val - Specificity: 0.7395, NPV: 0.9818\n",
      "---\n",
      "Epoch 85/2000, Loss: 0.3346\n",
      "Train - Acc: 0.7672, Precision: 0.1031, Recall: 0.8462\n",
      "Train - F1 (Macro): 0.5240, F1 (Micro): 0.7672\n",
      "Train - Specificity: 0.7647, NPV: 0.9936\n",
      "Val - Acc: 0.7383, Precision: 0.0887, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5006, F1 (Micro): 0.7383\n",
      "Val - Specificity: 0.7418, NPV: 0.9819\n",
      "---\n",
      "Epoch 86/2000, Loss: 0.3334\n",
      "Train - Acc: 0.7677, Precision: 0.1033, Recall: 0.8462\n",
      "Train - F1 (Macro): 0.5244, F1 (Micro): 0.7677\n",
      "Train - Specificity: 0.7652, NPV: 0.9936\n",
      "Val - Acc: 0.7390, Precision: 0.0889, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5010, F1 (Micro): 0.7390\n",
      "Val - Specificity: 0.7426, NPV: 0.9819\n",
      "---\n",
      "Epoch 87/2000, Loss: 0.3322\n",
      "Train - Acc: 0.7699, Precision: 0.1042, Recall: 0.8462\n",
      "Train - F1 (Macro): 0.5258, F1 (Micro): 0.7699\n",
      "Train - Specificity: 0.7675, NPV: 0.9936\n",
      "Val - Acc: 0.7412, Precision: 0.0874, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5004, F1 (Micro): 0.7412\n",
      "Val - Specificity: 0.7456, NPV: 0.9810\n",
      "---\n",
      "Epoch 88/2000, Loss: 0.3311\n",
      "Train - Acc: 0.7707, Precision: 0.1045, Recall: 0.8462\n",
      "Train - F1 (Macro): 0.5263, F1 (Micro): 0.7707\n",
      "Train - Specificity: 0.7683, NPV: 0.9936\n",
      "Val - Acc: 0.7419, Precision: 0.0877, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5008, F1 (Micro): 0.7419\n",
      "Val - Specificity: 0.7464, NPV: 0.9810\n",
      "---\n",
      "Epoch 89/2000, Loss: 0.3299\n",
      "Train - Acc: 0.7703, Precision: 0.1044, Recall: 0.8462\n",
      "Train - F1 (Macro): 0.5261, F1 (Micro): 0.7703\n",
      "Train - Specificity: 0.7679, NPV: 0.9936\n",
      "Val - Acc: 0.7412, Precision: 0.0874, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5004, F1 (Micro): 0.7412\n",
      "Val - Specificity: 0.7456, NPV: 0.9810\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/2000, Loss: 0.3287\n",
      "Train - Acc: 0.7687, Precision: 0.1037, Recall: 0.8462\n",
      "Train - F1 (Macro): 0.5250, F1 (Micro): 0.7687\n",
      "Train - Specificity: 0.7662, NPV: 0.9936\n",
      "Val - Acc: 0.7412, Precision: 0.0874, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5004, F1 (Micro): 0.7412\n",
      "Val - Specificity: 0.7456, NPV: 0.9810\n",
      "---\n",
      "Epoch 91/2000, Loss: 0.3276\n",
      "Train - Acc: 0.7688, Precision: 0.1038, Recall: 0.8462\n",
      "Train - F1 (Macro): 0.5251, F1 (Micro): 0.7688\n",
      "Train - Specificity: 0.7664, NPV: 0.9936\n",
      "Val - Acc: 0.7419, Precision: 0.0877, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5008, F1 (Micro): 0.7419\n",
      "Val - Specificity: 0.7464, NPV: 0.9810\n",
      "---\n",
      "Epoch 92/2000, Loss: 0.3265\n",
      "Train - Acc: 0.7674, Precision: 0.1037, Recall: 0.8521\n",
      "Train - F1 (Macro): 0.5246, F1 (Micro): 0.7674\n",
      "Train - Specificity: 0.7647, NPV: 0.9939\n",
      "Val - Acc: 0.7405, Precision: 0.0872, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.4999, F1 (Micro): 0.7405\n",
      "Val - Specificity: 0.7449, NPV: 0.9809\n",
      "---\n",
      "Epoch 93/2000, Loss: 0.3253\n",
      "Train - Acc: 0.7683, Precision: 0.1047, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5258, F1 (Micro): 0.7683\n",
      "Train - Specificity: 0.7654, NPV: 0.9941\n",
      "Val - Acc: 0.7412, Precision: 0.0874, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5004, F1 (Micro): 0.7412\n",
      "Val - Specificity: 0.7456, NPV: 0.9810\n",
      "---\n",
      "Epoch 94/2000, Loss: 0.3242\n",
      "Train - Acc: 0.7679, Precision: 0.1045, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5255, F1 (Micro): 0.7679\n",
      "Train - Specificity: 0.7650, NPV: 0.9941\n",
      "Val - Acc: 0.7397, Precision: 0.0870, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.4995, F1 (Micro): 0.7397\n",
      "Val - Specificity: 0.7441, NPV: 0.9809\n",
      "---\n",
      "Epoch 95/2000, Loss: 0.3231\n",
      "Train - Acc: 0.7677, Precision: 0.1045, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5254, F1 (Micro): 0.7677\n",
      "Train - Specificity: 0.7649, NPV: 0.9941\n",
      "Val - Acc: 0.7383, Precision: 0.0865, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.4986, F1 (Micro): 0.7383\n",
      "Val - Specificity: 0.7426, NPV: 0.9809\n",
      "---\n",
      "Epoch 96/2000, Loss: 0.3220\n",
      "Train - Acc: 0.7685, Precision: 0.1048, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5259, F1 (Micro): 0.7685\n",
      "Train - Specificity: 0.7656, NPV: 0.9941\n",
      "Val - Acc: 0.7390, Precision: 0.0867, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.4991, F1 (Micro): 0.7390\n",
      "Val - Specificity: 0.7433, NPV: 0.9809\n",
      "---\n",
      "Epoch 97/2000, Loss: 0.3209\n",
      "Train - Acc: 0.7709, Precision: 0.1058, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5275, F1 (Micro): 0.7709\n",
      "Train - Specificity: 0.7681, NPV: 0.9941\n",
      "Val - Acc: 0.7412, Precision: 0.0874, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5004, F1 (Micro): 0.7412\n",
      "Val - Specificity: 0.7456, NPV: 0.9810\n",
      "---\n",
      "Epoch 98/2000, Loss: 0.3198\n",
      "Train - Acc: 0.7718, Precision: 0.1061, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5281, F1 (Micro): 0.7718\n",
      "Train - Specificity: 0.7690, NPV: 0.9941\n",
      "Val - Acc: 0.7434, Precision: 0.0904, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5036, F1 (Micro): 0.7434\n",
      "Val - Specificity: 0.7471, NPV: 0.9820\n",
      "---\n",
      "Epoch 99/2000, Loss: 0.3187\n",
      "Train - Acc: 0.7720, Precision: 0.1062, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5282, F1 (Micro): 0.7720\n",
      "Train - Specificity: 0.7692, NPV: 0.9941\n",
      "Val - Acc: 0.7412, Precision: 0.0897, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5023, F1 (Micro): 0.7412\n",
      "Val - Specificity: 0.7449, NPV: 0.9819\n",
      "---\n",
      "Epoch 100/2000, Loss: 0.3176\n",
      "Train - Acc: 0.7753, Precision: 0.1076, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5304, F1 (Micro): 0.7753\n",
      "Train - Specificity: 0.7726, NPV: 0.9942\n",
      "Val - Acc: 0.7434, Precision: 0.0904, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5036, F1 (Micro): 0.7434\n",
      "Val - Specificity: 0.7471, NPV: 0.9820\n",
      "---\n",
      "Epoch 101/2000, Loss: 0.3165\n",
      "Train - Acc: 0.7775, Precision: 0.1086, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5319, F1 (Micro): 0.7775\n",
      "Train - Specificity: 0.7749, NPV: 0.9942\n",
      "Val - Acc: 0.7441, Precision: 0.0884, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5021, F1 (Micro): 0.7441\n",
      "Val - Specificity: 0.7487, NPV: 0.9810\n",
      "---\n",
      "Epoch 102/2000, Loss: 0.3155\n",
      "Train - Acc: 0.7767, Precision: 0.1083, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5314, F1 (Micro): 0.7767\n",
      "Train - Specificity: 0.7741, NPV: 0.9942\n",
      "Val - Acc: 0.7434, Precision: 0.0882, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5017, F1 (Micro): 0.7434\n",
      "Val - Specificity: 0.7479, NPV: 0.9810\n",
      "---\n",
      "Epoch 103/2000, Loss: 0.3144\n",
      "Train - Acc: 0.7764, Precision: 0.1081, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5311, F1 (Micro): 0.7764\n",
      "Train - Specificity: 0.7737, NPV: 0.9942\n",
      "Val - Acc: 0.7434, Precision: 0.0882, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5017, F1 (Micro): 0.7434\n",
      "Val - Specificity: 0.7479, NPV: 0.9810\n",
      "---\n",
      "Epoch 104/2000, Loss: 0.3133\n",
      "Train - Acc: 0.7789, Precision: 0.1093, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5329, F1 (Micro): 0.7789\n",
      "Train - Specificity: 0.7764, NPV: 0.9942\n",
      "Val - Acc: 0.7463, Precision: 0.0891, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5034, F1 (Micro): 0.7463\n",
      "Val - Specificity: 0.7510, NPV: 0.9811\n",
      "---\n",
      "Epoch 105/2000, Loss: 0.3122\n",
      "Train - Acc: 0.7769, Precision: 0.1090, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5320, F1 (Micro): 0.7769\n",
      "Train - Specificity: 0.7741, NPV: 0.9944\n",
      "Val - Acc: 0.7456, Precision: 0.0889, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5030, F1 (Micro): 0.7456\n",
      "Val - Specificity: 0.7502, NPV: 0.9811\n",
      "---\n",
      "Epoch 106/2000, Loss: 0.3112\n",
      "Train - Acc: 0.7769, Precision: 0.1090, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5320, F1 (Micro): 0.7769\n",
      "Train - Specificity: 0.7741, NPV: 0.9944\n",
      "Val - Acc: 0.7427, Precision: 0.0879, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5012, F1 (Micro): 0.7427\n",
      "Val - Specificity: 0.7471, NPV: 0.9810\n",
      "---\n",
      "Epoch 107/2000, Loss: 0.3101\n",
      "Train - Acc: 0.7775, Precision: 0.1092, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5324, F1 (Micro): 0.7775\n",
      "Train - Specificity: 0.7747, NPV: 0.9944\n",
      "Val - Acc: 0.7463, Precision: 0.0891, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5034, F1 (Micro): 0.7463\n",
      "Val - Specificity: 0.7510, NPV: 0.9811\n",
      "---\n",
      "Epoch 108/2000, Loss: 0.3091\n",
      "Train - Acc: 0.7784, Precision: 0.1096, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5330, F1 (Micro): 0.7784\n",
      "Train - Specificity: 0.7756, NPV: 0.9944\n",
      "Val - Acc: 0.7456, Precision: 0.0889, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5030, F1 (Micro): 0.7456\n",
      "Val - Specificity: 0.7502, NPV: 0.9811\n",
      "---\n",
      "Epoch 109/2000, Loss: 0.3081\n",
      "Train - Acc: 0.7780, Precision: 0.1094, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5328, F1 (Micro): 0.7780\n",
      "Train - Specificity: 0.7753, NPV: 0.9944\n",
      "Val - Acc: 0.7434, Precision: 0.0882, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5017, F1 (Micro): 0.7434\n",
      "Val - Specificity: 0.7479, NPV: 0.9810\n",
      "---\n",
      "Epoch 110/2000, Loss: 0.3071\n",
      "Train - Acc: 0.7782, Precision: 0.1095, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5329, F1 (Micro): 0.7782\n",
      "Train - Specificity: 0.7754, NPV: 0.9944\n",
      "Val - Acc: 0.7427, Precision: 0.0879, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5012, F1 (Micro): 0.7427\n",
      "Val - Specificity: 0.7471, NPV: 0.9810\n",
      "---\n",
      "Epoch 111/2000, Loss: 0.3060\n",
      "Train - Acc: 0.7806, Precision: 0.1106, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5345, F1 (Micro): 0.7806\n",
      "Train - Specificity: 0.7779, NPV: 0.9944\n",
      "Val - Acc: 0.7434, Precision: 0.0882, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5017, F1 (Micro): 0.7434\n",
      "Val - Specificity: 0.7479, NPV: 0.9810\n",
      "---\n",
      "Epoch 112/2000, Loss: 0.3050\n",
      "Train - Acc: 0.7782, Precision: 0.1095, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5329, F1 (Micro): 0.7782\n",
      "Train - Specificity: 0.7754, NPV: 0.9944\n",
      "Val - Acc: 0.7434, Precision: 0.0904, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5036, F1 (Micro): 0.7434\n",
      "Val - Specificity: 0.7471, NPV: 0.9820\n",
      "---\n",
      "Epoch 113/2000, Loss: 0.3039\n",
      "Train - Acc: 0.7756, Precision: 0.1084, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5312, F1 (Micro): 0.7756\n",
      "Train - Specificity: 0.7728, NPV: 0.9944\n",
      "Val - Acc: 0.7405, Precision: 0.0894, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5019, F1 (Micro): 0.7405\n",
      "Val - Specificity: 0.7441, NPV: 0.9819\n",
      "---\n",
      "Epoch 114/2000, Loss: 0.3029\n",
      "Train - Acc: 0.7775, Precision: 0.1092, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5324, F1 (Micro): 0.7775\n",
      "Train - Specificity: 0.7747, NPV: 0.9944\n",
      "Val - Acc: 0.7434, Precision: 0.0904, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5036, F1 (Micro): 0.7434\n",
      "Val - Specificity: 0.7471, NPV: 0.9820\n",
      "---\n",
      "Epoch 115/2000, Loss: 0.3018\n",
      "Train - Acc: 0.7824, Precision: 0.1115, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5358, F1 (Micro): 0.7824\n",
      "Train - Specificity: 0.7798, NPV: 0.9945\n",
      "Val - Acc: 0.7471, Precision: 0.0917, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5058, F1 (Micro): 0.7471\n",
      "Val - Specificity: 0.7510, NPV: 0.9821\n",
      "---\n",
      "Epoch 116/2000, Loss: 0.3009\n",
      "Train - Acc: 0.7802, Precision: 0.1110, Recall: 0.8698\n",
      "Train - F1 (Macro): 0.5348, F1 (Micro): 0.7802\n",
      "Train - Specificity: 0.7773, NPV: 0.9947\n",
      "Val - Acc: 0.7434, Precision: 0.0904, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5036, F1 (Micro): 0.7434\n",
      "Val - Specificity: 0.7471, NPV: 0.9820\n",
      "---\n",
      "Epoch 117/2000, Loss: 0.2998\n",
      "Train - Acc: 0.7809, Precision: 0.1114, Recall: 0.8698\n",
      "Train - F1 (Macro): 0.5353, F1 (Micro): 0.7809\n",
      "Train - Specificity: 0.7781, NPV: 0.9947\n",
      "Val - Acc: 0.7441, Precision: 0.0907, Recall: 0.6471\n",
      "Val - F1 (Macro): 0.5041, F1 (Micro): 0.7441\n",
      "Val - Specificity: 0.7479, NPV: 0.9820\n",
      "---\n",
      "Epoch 118/2000, Loss: 0.2988\n",
      "Train - Acc: 0.7848, Precision: 0.1126, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5374, F1 (Micro): 0.7848\n",
      "Train - Specificity: 0.7823, NPV: 0.9945\n",
      "Val - Acc: 0.7500, Precision: 0.0904, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5056, F1 (Micro): 0.7500\n",
      "Val - Specificity: 0.7548, NPV: 0.9812\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/2000, Loss: 0.2978\n",
      "Train - Acc: 0.7850, Precision: 0.1127, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5376, F1 (Micro): 0.7850\n",
      "Train - Specificity: 0.7824, NPV: 0.9945\n",
      "Val - Acc: 0.7471, Precision: 0.0894, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5039, F1 (Micro): 0.7471\n",
      "Val - Specificity: 0.7517, NPV: 0.9811\n",
      "---\n",
      "Epoch 120/2000, Loss: 0.2967\n",
      "Train - Acc: 0.7874, Precision: 0.1138, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5392, F1 (Micro): 0.7874\n",
      "Train - Specificity: 0.7849, NPV: 0.9945\n",
      "Val - Acc: 0.7537, Precision: 0.0917, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5078, F1 (Micro): 0.7537\n",
      "Val - Specificity: 0.7586, NPV: 0.9813\n",
      "---\n",
      "Epoch 121/2000, Loss: 0.2957\n",
      "Train - Acc: 0.7908, Precision: 0.1155, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5417, F1 (Micro): 0.7908\n",
      "Train - Specificity: 0.7885, NPV: 0.9945\n",
      "Val - Acc: 0.7566, Precision: 0.0928, Recall: 0.6275\n",
      "Val - F1 (Macro): 0.5096, F1 (Micro): 0.7566\n",
      "Val - Specificity: 0.7616, NPV: 0.9814\n",
      "---\n",
      "Epoch 122/2000, Loss: 0.2946\n",
      "Train - Acc: 0.7923, Precision: 0.1162, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5427, F1 (Micro): 0.7923\n",
      "Train - Specificity: 0.7900, NPV: 0.9945\n",
      "Val - Acc: 0.7625, Precision: 0.0925, Recall: 0.6078\n",
      "Val - F1 (Macro): 0.5111, F1 (Micro): 0.7625\n",
      "Val - Specificity: 0.7685, NPV: 0.9806\n",
      "---\n",
      "Epoch 123/2000, Loss: 0.2936\n",
      "Train - Acc: 0.7969, Precision: 0.1180, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5455, F1 (Micro): 0.7969\n",
      "Train - Specificity: 0.7949, NPV: 0.9943\n",
      "Val - Acc: 0.7639, Precision: 0.0931, Recall: 0.6078\n",
      "Val - F1 (Macro): 0.5120, F1 (Micro): 0.7639\n",
      "Val - Specificity: 0.7700, NPV: 0.9806\n",
      "---\n",
      "Epoch 124/2000, Loss: 0.2926\n",
      "Train - Acc: 0.8029, Precision: 0.1212, Recall: 0.8580\n",
      "Train - F1 (Macro): 0.5499, F1 (Micro): 0.8029\n",
      "Train - Specificity: 0.8012, NPV: 0.9944\n",
      "Val - Acc: 0.7683, Precision: 0.0923, Recall: 0.5882\n",
      "Val - F1 (Macro): 0.5126, F1 (Micro): 0.7683\n",
      "Val - Specificity: 0.7753, NPV: 0.9798\n",
      "---\n",
      "Epoch 125/2000, Loss: 0.2916\n",
      "Train - Acc: 0.8037, Precision: 0.1223, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5510, F1 (Micro): 0.8037\n",
      "Train - Specificity: 0.8017, NPV: 0.9946\n",
      "Val - Acc: 0.7669, Precision: 0.0917, Recall: 0.5882\n",
      "Val - F1 (Macro): 0.5117, F1 (Micro): 0.7669\n",
      "Val - Specificity: 0.7738, NPV: 0.9797\n",
      "---\n",
      "Epoch 126/2000, Loss: 0.2905\n",
      "Train - Acc: 0.8035, Precision: 0.1222, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5509, F1 (Micro): 0.8035\n",
      "Train - Specificity: 0.8016, NPV: 0.9946\n",
      "Val - Acc: 0.7669, Precision: 0.0917, Recall: 0.5882\n",
      "Val - F1 (Macro): 0.5117, F1 (Micro): 0.7669\n",
      "Val - Specificity: 0.7738, NPV: 0.9797\n",
      "---\n",
      "Epoch 127/2000, Loss: 0.2895\n",
      "Train - Acc: 0.8016, Precision: 0.1212, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5495, F1 (Micro): 0.8016\n",
      "Train - Specificity: 0.7997, NPV: 0.9946\n",
      "Val - Acc: 0.7632, Precision: 0.0879, Recall: 0.5686\n",
      "Val - F1 (Macro): 0.5073, F1 (Micro): 0.7632\n",
      "Val - Specificity: 0.7708, NPV: 0.9787\n",
      "---\n",
      "Epoch 128/2000, Loss: 0.2885\n",
      "Train - Acc: 0.8037, Precision: 0.1223, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5510, F1 (Micro): 0.8037\n",
      "Train - Specificity: 0.8017, NPV: 0.9946\n",
      "Val - Acc: 0.7632, Precision: 0.0879, Recall: 0.5686\n",
      "Val - F1 (Macro): 0.5073, F1 (Micro): 0.7632\n",
      "Val - Specificity: 0.7708, NPV: 0.9787\n",
      "---\n",
      "Epoch 129/2000, Loss: 0.2875\n",
      "Train - Acc: 0.8049, Precision: 0.1230, Recall: 0.8639\n",
      "Train - F1 (Macro): 0.5520, F1 (Micro): 0.8049\n",
      "Train - Specificity: 0.8031, NPV: 0.9946\n",
      "Val - Acc: 0.7654, Precision: 0.0887, Recall: 0.5686\n",
      "Val - F1 (Macro): 0.5086, F1 (Micro): 0.7654\n",
      "Val - Specificity: 0.7730, NPV: 0.9788\n",
      "---\n",
      "Epoch 130/2000, Loss: 0.2865\n",
      "Train - Acc: 0.8049, Precision: 0.1236, Recall: 0.8698\n",
      "Train - F1 (Macro): 0.5526, F1 (Micro): 0.8049\n",
      "Train - Specificity: 0.8029, NPV: 0.9948\n",
      "Val - Acc: 0.7676, Precision: 0.0895, Recall: 0.5686\n",
      "Val - F1 (Macro): 0.5100, F1 (Micro): 0.7676\n",
      "Val - Specificity: 0.7753, NPV: 0.9788\n",
      "---\n",
      "Epoch 131/2000, Loss: 0.2855\n",
      "Train - Acc: 0.8075, Precision: 0.1251, Recall: 0.8698\n",
      "Train - F1 (Macro): 0.5545, F1 (Micro): 0.8075\n",
      "Train - Specificity: 0.8055, NPV: 0.9949\n",
      "Val - Acc: 0.7698, Precision: 0.0903, Recall: 0.5686\n",
      "Val - F1 (Macro): 0.5113, F1 (Micro): 0.7698\n",
      "Val - Specificity: 0.7776, NPV: 0.9789\n",
      "---\n",
      "Epoch 132/2000, Loss: 0.2845\n",
      "Train - Acc: 0.8084, Precision: 0.1263, Recall: 0.8757\n",
      "Train - F1 (Macro): 0.5558, F1 (Micro): 0.8084\n",
      "Train - Specificity: 0.8063, NPV: 0.9951\n",
      "Val - Acc: 0.7705, Precision: 0.0906, Recall: 0.5686\n",
      "Val - F1 (Macro): 0.5118, F1 (Micro): 0.7705\n",
      "Val - Specificity: 0.7784, NPV: 0.9789\n",
      "---\n",
      "Epoch 133/2000, Loss: 0.2835\n",
      "Train - Acc: 0.8035, Precision: 0.1234, Recall: 0.8757\n",
      "Train - F1 (Macro): 0.5520, F1 (Micro): 0.8035\n",
      "Train - Specificity: 0.8012, NPV: 0.9951\n",
      "Val - Acc: 0.7705, Precision: 0.0957, Recall: 0.6078\n",
      "Val - F1 (Macro): 0.5162, F1 (Micro): 0.7705\n",
      "Val - Specificity: 0.7768, NPV: 0.9808\n",
      "---\n",
      "Epoch 134/2000, Loss: 0.2824\n",
      "Train - Acc: 0.8060, Precision: 0.1249, Recall: 0.8757\n",
      "Train - F1 (Macro): 0.5539, F1 (Micro): 0.8060\n",
      "Train - Specificity: 0.8038, NPV: 0.9951\n",
      "Val - Acc: 0.7713, Precision: 0.0960, Recall: 0.6078\n",
      "Val - F1 (Macro): 0.5166, F1 (Micro): 0.7713\n",
      "Val - Specificity: 0.7776, NPV: 0.9808\n",
      "---\n",
      "Epoch 135/2000, Loss: 0.2814\n",
      "Train - Acc: 0.8141, Precision: 0.1304, Recall: 0.8817\n",
      "Train - F1 (Macro): 0.5607, F1 (Micro): 0.8141\n",
      "Train - Specificity: 0.8120, NPV: 0.9954\n",
      "Val - Acc: 0.7764, Precision: 0.0981, Recall: 0.6078\n",
      "Val - F1 (Macro): 0.5199, F1 (Micro): 0.7764\n",
      "Val - Specificity: 0.7829, NPV: 0.9809\n",
      "---\n",
      "Epoch 136/2000, Loss: 0.2805\n",
      "Train - Acc: 0.8055, Precision: 0.1252, Recall: 0.8817\n",
      "Train - F1 (Macro): 0.5541, F1 (Micro): 0.8055\n",
      "Train - Specificity: 0.8031, NPV: 0.9953\n",
      "Val - Acc: 0.7705, Precision: 0.0957, Recall: 0.6078\n",
      "Val - F1 (Macro): 0.5162, F1 (Micro): 0.7705\n",
      "Val - Specificity: 0.7768, NPV: 0.9808\n",
      "---\n",
      "Epoch 137/2000, Loss: 0.2794\n",
      "Train - Acc: 0.8018, Precision: 0.1238, Recall: 0.8876\n",
      "Train - F1 (Macro): 0.5519, F1 (Micro): 0.8018\n",
      "Train - Specificity: 0.7991, NPV: 0.9955\n",
      "Val - Acc: 0.7654, Precision: 0.0937, Recall: 0.6078\n",
      "Val - F1 (Macro): 0.5130, F1 (Micro): 0.7654\n",
      "Val - Specificity: 0.7715, NPV: 0.9806\n",
      "---\n",
      "Epoch 138/2000, Loss: 0.2784\n",
      "Train - Acc: 0.8031, Precision: 0.1245, Recall: 0.8876\n",
      "Train - F1 (Macro): 0.5529, F1 (Micro): 0.8031\n",
      "Train - Specificity: 0.8004, NPV: 0.9955\n",
      "Val - Acc: 0.7654, Precision: 0.0937, Recall: 0.6078\n",
      "Val - F1 (Macro): 0.5130, F1 (Micro): 0.7654\n",
      "Val - Specificity: 0.7715, NPV: 0.9806\n",
      "---\n",
      "Epoch 139/2000, Loss: 0.2774\n",
      "Train - Acc: 0.8051, Precision: 0.1256, Recall: 0.8876\n",
      "Train - F1 (Macro): 0.5544, F1 (Micro): 0.8051\n",
      "Train - Specificity: 0.8025, NPV: 0.9955\n",
      "Val - Acc: 0.7676, Precision: 0.0920, Recall: 0.5882\n",
      "Val - F1 (Macro): 0.5122, F1 (Micro): 0.7676\n",
      "Val - Specificity: 0.7746, NPV: 0.9798\n",
      "---\n",
      "Epoch 140/2000, Loss: 0.2764\n",
      "Train - Acc: 0.8093, Precision: 0.1281, Recall: 0.8876\n",
      "Train - F1 (Macro): 0.5576, F1 (Micro): 0.8093\n",
      "Train - Specificity: 0.8068, NPV: 0.9956\n",
      "Val - Acc: 0.7727, Precision: 0.0940, Recall: 0.5882\n",
      "Val - F1 (Macro): 0.5153, F1 (Micro): 0.7727\n",
      "Val - Specificity: 0.7799, NPV: 0.9799\n",
      "---\n",
      "Epoch 141/2000, Loss: 0.2754\n",
      "Train - Acc: 0.8070, Precision: 0.1273, Recall: 0.8935\n",
      "Train - F1 (Macro): 0.5563, F1 (Micro): 0.8070\n",
      "Train - Specificity: 0.8042, NPV: 0.9958\n",
      "Val - Acc: 0.7698, Precision: 0.0878, Recall: 0.5490\n",
      "Val - F1 (Macro): 0.5091, F1 (Micro): 0.7698\n",
      "Val - Specificity: 0.7784, NPV: 0.9780\n",
      "---\n",
      "Epoch 142/2000, Loss: 0.2744\n",
      "Train - Acc: 0.8128, Precision: 0.1308, Recall: 0.8935\n",
      "Train - F1 (Macro): 0.5609, F1 (Micro): 0.8128\n",
      "Train - Specificity: 0.8103, NPV: 0.9958\n",
      "Val - Acc: 0.7764, Precision: 0.0903, Recall: 0.5490\n",
      "Val - F1 (Macro): 0.5131, F1 (Micro): 0.7764\n",
      "Val - Specificity: 0.7852, NPV: 0.9782\n",
      "---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m train_precision \u001b[38;5;241m=\u001b[39m precision_score(y_train\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_preds, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     90\u001b[0m train_recall \u001b[38;5;241m=\u001b[39m recall_score(y_train\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_preds)\n\u001b[1;32m---> 91\u001b[0m train_f1_macro \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m train_f1_micro \u001b[38;5;241m=\u001b[39m f1_score(y_train\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     93\u001b[0m tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m confusion_matrix(y_train\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_preds)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[0;32m   1012\u001b[0m     y_true,\n\u001b[0;32m   1013\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1020\u001b[0m ):\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \n\u001b[0;32m   1023\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[0;32m   1159\u001b[0m     y_true,\n\u001b[0;32m   1160\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1168\u001b[0m ):\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \n\u001b[0;32m   1171\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\metrics\\_classification.py:113\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m         unique_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    120\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot y_true=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y_true)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe true labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munion1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\numpy\\lib\\arraysetops.py:781\u001b[0m, in \u001b[0;36munion1d\u001b[1;34m(ar1, ar2)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_union1d_dispatcher)\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munion1d\u001b[39m(ar1, ar2):\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;124;03m    Find the union of two arrays.\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;124;03m    array([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix\n",
    "\n",
    "# 读取CSV文件\n",
    "data = pd.read_csv('taiwan_bankrupt_data.csv').dropna()\n",
    "\n",
    "# 分割特征和标签\n",
    "features = data.iloc[:, :-1].values\n",
    "labels = data.iloc[:, -1].values\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 转换为Tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# 定义神经网络模型\n",
    "#第一层全连接将原始数据映射至64维，第二层将64维再重新线性组合为64维，最终输出1维结果\n",
    "#层与层之间进行批量归一化，以及RELU激活函数\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型和优化器\n",
    "input_size = X_train.shape[1]\n",
    "model = Net(input_size)\n",
    "#采用Adam优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#二分类交叉熵损失\n",
    "#pos_weight为两类损失比，即小类样本的计算损失fang'da\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(5))\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# 记录指标的列表\n",
    "train_acc_list = []\n",
    "train_precision_list = []\n",
    "train_recall_list = []\n",
    "train_f1_macro_list = []\n",
    "train_f1_micro_list = []\n",
    "train_specificity_list = []\n",
    "train_npv_list = []\n",
    "\n",
    "val_acc_list = []\n",
    "val_precision_list = []\n",
    "val_recall_list = []\n",
    "val_f1_macro_list = []\n",
    "val_f1_micro_list = []\n",
    "val_specificity_list = []\n",
    "val_npv_list = []\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 2000\n",
    "threshold = 0.2\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs, eta_min=0, last_epoch=-1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    predictions = (torch.sigmoid(outputs) >= threshold).float().squeeze()\n",
    "    loss = criterion(outputs, y_train.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    # 在训练集上计算指标\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_preds = (torch.sigmoid(model(X_train)) >= threshold).float().squeeze().detach().numpy()\n",
    "        train_acc = accuracy_score(y_train.detach().numpy(), train_preds)\n",
    "        train_precision = precision_score(y_train.detach().numpy(), train_preds, zero_division=0)\n",
    "        train_recall = recall_score(y_train.detach().numpy(), train_preds)\n",
    "        train_f1_macro = f1_score(y_train.detach().numpy(), train_preds, average='macro')\n",
    "        train_f1_micro = f1_score(y_train.detach().numpy(), train_preds, average='micro')\n",
    "        tn, fp, fn, tp = confusion_matrix(y_train.detach().numpy(), train_preds).ravel()\n",
    "        train_specificity = tn / (tn + fp)\n",
    "        if tn == 0:\n",
    "            train_npv = 0\n",
    "        else :\n",
    "            train_npv = tn / (tn + fn)\n",
    "\n",
    "    # 在验证集上计算指标\n",
    "    with torch.no_grad():\n",
    "        val_preds = (torch.sigmoid(model(X_val)) >= threshold).float().squeeze().detach().numpy()\n",
    "        val_acc = accuracy_score(y_val.detach().numpy(), val_preds)\n",
    "        val_precision = precision_score(y_val.detach().numpy(), val_preds, zero_division=0)\n",
    "        val_recall = recall_score(y_val.detach().numpy(), val_preds)\n",
    "        val_f1_macro = f1_score(y_val.detach().numpy(), val_preds, average='macro')\n",
    "        val_f1_micro = f1_score(y_val.detach().numpy(), val_preds, average='micro')\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val.detach().numpy(), val_preds).ravel()\n",
    "        val_specificity = tn / (tn + fp)\n",
    "        if tn == 0:\n",
    "            val_npv = 0\n",
    "        else :\n",
    "            val_npv = tn / (tn + fn)\n",
    "    if val_acc == 1:\n",
    "        break\n",
    "    # 记录指标\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_precision_list.append(train_precision)\n",
    "    train_recall_list.append(train_recall)\n",
    "    train_f1_macro_list.append(train_f1_macro)\n",
    "    train_f1_micro_list.append(train_f1_micro)\n",
    "    train_specificity_list.append(train_specificity)\n",
    "    train_npv_list.append(train_npv)\n",
    "\n",
    "    val_acc_list.append(val_acc)\n",
    "    val_precision_list.append(val_precision)\n",
    "    val_recall_list.append(val_recall)\n",
    "    val_f1_macro_list.append(val_f1_macro)\n",
    "    val_f1_micro_list.append(val_f1_micro)\n",
    "    val_specificity_list.append(val_specificity)\n",
    "    val_npv_list.append(val_npv)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}')\n",
    "    print(f'Train - Acc: {train_acc:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}')\n",
    "    print(f'Train - F1 (Macro): {train_f1_macro:.4f}, F1 (Micro): {train_f1_micro:.4f}')\n",
    "    print(f'Train - Specificity: {train_specificity:.4f}, NPV: {train_npv:.4f}')\n",
    "    print(f'Val - Acc: {val_acc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}')\n",
    "    print(f'Val - F1 (Macro): {val_f1_macro:.4f}, F1 (Micro): {val_f1_micro:.4f}')\n",
    "    print(f'Val - Specificity: {val_specificity:.4f}, NPV: {val_npv:.4f}')\n",
    "    print('---')\n",
    "\n",
    "# 将训练集和测试集的指标保存为DataFrame\n",
    "train_metrics = pd.DataFrame({\n",
    "    'Accuracy': train_acc_list,\n",
    "    'Precision': train_precision_list,\n",
    "    'Recall': train_recall_list,\n",
    "    'F1 Macro': train_f1_macro_list,\n",
    "    'F1 Micro': train_f1_micro_list,\n",
    "    'Specificity': train_specificity_list,\n",
    "    'NPV': train_npv_list\n",
    "})\n",
    "\n",
    "val_metrics = pd.DataFrame({\n",
    "    'Accuracy': val_acc_list,\n",
    "    'Precision': val_precision_list,\n",
    "    'Recall': val_recall_list,\n",
    "    'F1 Macro': val_f1_macro_list,\n",
    "    'F1 Micro': val_f1_micro_list,\n",
    "    'Specificity': val_specificity_list,\n",
    "    'NPV': val_npv_list\n",
    "})\n",
    "\n",
    "# 打印训练集的指标\n",
    "print(\"Train Metrics:\")\n",
    "print(train_metrics)\n",
    "\n",
    "# 打印测试集的指标\n",
    "print(\"Validation Metrics:\")\n",
    "print(val_metrics)\n",
    "\n",
    "# 绘制指标曲线\n",
    "epochs = range(1, num_epochs+1)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.plot(epochs, train_acc_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_acc_list, 'r', label='Val')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.plot(epochs, train_precision_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_precision_list, 'r', label='Val')\n",
    "plt.title('Precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.plot(epochs, train_recall_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_recall_list, 'r', label='Val')\n",
    "plt.title('Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "plt.plot(epochs, train_npv_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_npv_list, 'r', label='Val')\n",
    "plt.title('NPV')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NPV')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "plt.plot(epochs, train_specificity_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_specificity_list, 'r', label='Val')\n",
    "plt.title('Specificity')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Specificity')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "plt.plot(epochs, train_f1_macro_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_f1_macro_list, 'r', label='Val')\n",
    "plt.title('F1 Macro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Macro')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "plt.plot(epochs, train_f1_micro_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_f1_micro_list, 'r', label='Val')\n",
    "plt.title('F1 Micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Micro')\n",
    "plt.legend()\n",
    "\n",
    "#绘制训练曲线\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出收敛结果\n",
    "val_metrics.iloc[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
