{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacec50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix\n",
    "\n",
    "# 读取CSV文件\n",
    "data = pd.read_csv('credit_data_simulate.csv').dropna()\n",
    "\n",
    "# 分割特征和标签\n",
    "features = data.iloc[:, :-1].values\n",
    "labels = data.iloc[:, -1].values\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "y_train\n",
    "# 转换为Tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个三种嵌入的LSTM网络的类\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        # 定义三个嵌入层，每个嵌入层的输入大小为input_size，输出大小为embedding_size\n",
    "        self.embedding1 = nn.Linear(input_size, embedding_size)\n",
    "        self.bn1 = nn.BatchNorm1d(embedding_size) # 批归一化\n",
    "        self.embedding2 = nn.Linear(input_size, embedding_size)\n",
    "        self.bn2 = nn.BatchNorm1d(embedding_size) # 批归一化\n",
    "        self.embedding3 = nn.Linear(input_size, embedding_size)\n",
    "        self.bn3 = nn.BatchNorm1d(embedding_size) # 批归一化\n",
    "        # 定义一个LSTM层，输入大小为embedding_size，隐藏层大小为hidden_size，层数为num_layers\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
    "        # 定义一个全连接层，输入大小为hidden_size，输出大小为output_size\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        # 前向传播，输入x经过三个嵌入层和一个LSTM层，返回输出y\n",
    "        x1 = self.embedding1(x) # 第一个嵌入层\n",
    "        x1 = self.bn1(x1) # 批归一化\n",
    "        x1 = nn.ReLU()(x1) # 激活函数\n",
    "        x2 = self.embedding2(x) # 第二个嵌入层\n",
    "        x2 = self.bn2(x2) # 批归一化\n",
    "        x2 = nn.ReLU()(x2) # 激活函数\n",
    "        x3 = self.embedding3(x) # 第三个嵌入层\n",
    "        x3 = self.bn3(x3) # 批归一化\n",
    "        x3 = nn.ReLU()(x3) # 激活函数\n",
    "        x = torch.stack((x1, x2, x3), dim=2)# 拼接三个嵌入向量\n",
    "        x = torch.transpose(x, 1, 2) # 调换第二和第三维度\n",
    "        x, (h, c) = self.lstm(x) # LSTM层\n",
    "        x = x[:, -1,:] # 取最后一个时间步的输出\n",
    "        y = self.fc(x) # 全连接层做出最终预测\n",
    "        return y\n",
    "\n",
    "# 初始化模型和优化器\n",
    "input_size = X_train.shape[1]# 输入特征维度\n",
    "embedding_size = 64 # 嵌入特征维度\n",
    "hidden_size = 128 # LSTM隐藏层大小\n",
    "num_layers = 3 # LSTM层数\n",
    "output_size = 1 # 输出大小\n",
    "model = Net(input_size, embedding_size, hidden_size, num_layers, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(5))\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.BCELoss()\n",
    "# 记录指标的列表\n",
    "train_acc_list = []\n",
    "train_precision_list = []\n",
    "train_recall_list = []\n",
    "train_f1_macro_list = []\n",
    "train_f1_micro_list = []\n",
    "train_specificity_list = []\n",
    "train_npv_list = []\n",
    "\n",
    "val_acc_list = []\n",
    "val_precision_list = []\n",
    "val_recall_list = []\n",
    "val_f1_macro_list = []\n",
    "val_f1_micro_list = []\n",
    "val_specificity_list = []\n",
    "val_npv_list = []\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 20\n",
    "threshold = 0.5\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs, eta_min=0, last_epoch=-1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    predictions = (torch.sigmoid(outputs) >= threshold).float().squeeze()\n",
    "    loss = criterion(outputs, y_train.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    # 在训练集上计算指标\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        print(model(X_train))\n",
    "        train_preds = (model(X_train) >= threshold).float().squeeze().detach().numpy()\n",
    "        print(train_preds)\n",
    "        train_acc = accuracy_score(y_train.detach().numpy(), train_preds)\n",
    "        train_precision = precision_score(y_train.detach().numpy(), train_preds, zero_division=0)\n",
    "        train_recall = recall_score(y_train.detach().numpy(), train_preds)\n",
    "        train_f1_macro = f1_score(y_train.detach().numpy(), train_preds, average='macro')\n",
    "        train_f1_micro = f1_score(y_train.detach().numpy(), train_preds, average='micro')\n",
    "        tn, fp, fn, tp = confusion_matrix(y_train.detach().numpy(), train_preds).ravel()\n",
    "        train_specificity = tn / (tn + fp)\n",
    "        if tn == 0:\n",
    "            train_npv = 0\n",
    "        else :\n",
    "            train_npv = tn / (tn + fn)\n",
    "\n",
    "    # 在验证集上计算指标\n",
    "    with torch.no_grad():\n",
    "        val_preds = (torch.sigmoid(model(X_val)) >= threshold).float().squeeze().detach().numpy()\n",
    "        val_acc = accuracy_score(y_val.detach().numpy(), val_preds)\n",
    "        val_precision = precision_score(y_val.detach().numpy(), val_preds, zero_division=0)\n",
    "        val_recall = recall_score(y_val.detach().numpy(), val_preds)\n",
    "        val_f1_macro = f1_score(y_val.detach().numpy(), val_preds, average='macro')\n",
    "        val_f1_micro = f1_score(y_val.detach().numpy(), val_preds, average='micro')\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val.detach().numpy(), val_preds).ravel()\n",
    "        val_specificity = tn / (tn + fp)\n",
    "        if tn == 0:\n",
    "            val_npv = 0\n",
    "        else :\n",
    "            val_npv = tn / (tn + fn)\n",
    "#     if val_acc == 1:\n",
    "#         break\n",
    "    # 记录指标\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_precision_list.append(train_precision)\n",
    "    train_recall_list.append(train_recall)\n",
    "    train_f1_macro_list.append(train_f1_macro)\n",
    "    train_f1_micro_list.append(train_f1_micro)\n",
    "    train_specificity_list.append(train_specificity)\n",
    "    train_npv_list.append(train_npv)\n",
    "\n",
    "    val_acc_list.append(val_acc)\n",
    "    val_precision_list.append(val_precision)\n",
    "    val_recall_list.append(val_recall)\n",
    "    val_f1_macro_list.append(val_f1_macro)\n",
    "    val_f1_micro_list.append(val_f1_micro)\n",
    "    val_specificity_list.append(val_specificity)\n",
    "    val_npv_list.append(val_npv)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}')\n",
    "    print(f'Train - Acc: {train_acc:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}')\n",
    "    print(f'Train - F1 (Macro): {train_f1_macro:.4f}, F1 (Micro): {train_f1_micro:.4f}')\n",
    "    print(f'Train - Specificity: {train_specificity:.4f}, NPV: {train_npv:.4f}')\n",
    "    print(f'Val - Acc: {val_acc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}')\n",
    "    print(f'Val - F1 (Macro): {val_f1_macro:.4f}, F1 (Micro): {val_f1_micro:.4f}')\n",
    "    print(f'Val - Specificity: {val_specificity:.4f}, NPV: {val_npv:.4f}')\n",
    "    print('---')\n",
    "\n",
    "# 将训练集和测试集的指标保存为DataFrame\n",
    "train_metrics = pd.DataFrame({\n",
    "    'Accuracy': train_acc_list,\n",
    "    'Precision': train_precision_list,\n",
    "    'Recall': train_recall_list,\n",
    "    'F1 Macro': train_f1_macro_list,\n",
    "    'F1 Micro': train_f1_micro_list,\n",
    "    'Specificity': train_specificity_list,\n",
    "    'NPV': train_npv_list\n",
    "})\n",
    "\n",
    "val_metrics = pd.DataFrame({\n",
    "    'Accuracy': val_acc_list,\n",
    "    'Precision': val_precision_list,\n",
    "    'Recall': val_recall_list,\n",
    "    'F1 Macro': val_f1_macro_list,\n",
    "    'F1 Micro': val_f1_micro_list,\n",
    "    'Specificity': val_specificity_list,\n",
    "    'NPV': val_npv_list\n",
    "})\n",
    "\n",
    "# 打印训练集的指标\n",
    "print(\"Train Metrics:\")\n",
    "print(train_metrics)\n",
    "\n",
    "# 打印测试集的指标\n",
    "print(\"Validation Metrics:\")\n",
    "print(val_metrics)\n",
    "\n",
    "# 绘制指标曲线\n",
    "epochs = range(1, num_epochs+1)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.plot(epochs, train_acc_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_acc_list, 'r', label='Val')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.plot(epochs, train_precision_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_precision_list, 'r', label='Val')\n",
    "plt.title('Precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.plot(epochs, train_recall_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_recall_list, 'r', label='Val')\n",
    "plt.title('Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "plt.plot(epochs, train_npv_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_npv_list, 'r', label='Val')\n",
    "plt.title('NPV')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NPV')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "plt.plot(epochs, train_specificity_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_specificity_list, 'r', label='Val')\n",
    "plt.title('Specificity')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Specificity')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "plt.plot(epochs, train_f1_macro_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_f1_macro_list, 'r', label='Val')\n",
    "plt.title('F1 Macro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Macro')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "plt.plot(epochs, train_f1_micro_list, 'b', label='Train')\n",
    "plt.plot(epochs, val_f1_micro_list, 'r', label='Val')\n",
    "plt.title('F1 Micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Micro')\n",
    "plt.legend()\n",
    "#绘制训练曲线\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出收敛结果\n",
    "val_metrics.iloc[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
